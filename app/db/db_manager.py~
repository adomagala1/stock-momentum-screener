# app/db/db_manager.py

from sqlalchemy import text
from app.db.mongodb import news_col, update_news_for_ticker
from app.web.supabase_client import supabase
from sqlalchemy import inspect
from sqlalchemy import Table, Column, String, Float, MetaData, DateTime
from sqlalchemy.exc import ProgrammingError
import pandas as pd
from datetime import datetime
from app.db.postgresql import engine as pg_engine
import logging


logging.basicConfig(
    level=logging.INFO,
    filename="logs/db_manager.log",
    format="%(asctime)s [%(levelname)s] %(message)s"
)


# ==================== USER MANAGEMENT (SUPABASE) ====================

def get_user_by_email(email: str):
    """Zwraca u≈ºytkownika z Supabase na podstawie emaila"""
    resp = supabase.table("users").select("*").eq("email", email).execute()
    return resp.data[0] if resp.data else None


def get_user_watchlist(user_id: str) -> list:
    """Zwraca tickery z watchlisty u≈ºytkownika"""
    resp = supabase.table("watchlist").select("ticker").eq("user_id", user_id).execute()
    return [r["ticker"] for r in resp.data] if resp.data else []


def add_to_watchlist(user_id: str, ticker: str):
    """Dodaje ticker do watchlisty u≈ºytkownika"""
    supabase.table("watchlist").insert({"user_id": user_id, "ticker": ticker}).execute()
    logging.info(f"[WATCHLIST] Dodano {ticker} dla u≈ºytkownika {user_id}")


def remove_from_watchlist(user_id: str, ticker: str):
    """Usuwa ticker z watchlisty"""
    supabase.table("watchlist").delete().eq("user_id", user_id).eq("ticker", ticker).execute()
    logging.info(f"[WATCHLIST] Usuniƒôto {ticker} z watchlisty u≈ºytkownika {user_id}")


# ==================== STOCK DATA (POSTGRESQL) ====================

def get_stocks_from_db(limit=100):
    """Pobiera najnowsze dane gie≈Çdowe"""
    query = f"SELECT * FROM stocks_data ORDER BY import_date DESC LIMIT {limit}"
    with pg_engine.begin() as conn:
        df = pd.read_sql(query, conn)
    return df


def get_stock_details(ticker: str):
    """Pobiera dane konkretnego tickera"""
    query = text("SELECT * FROM stocks_data WHERE ticker = :ticker ORDER BY import_date DESC LIMIT 1")
    with pg_engine.begin() as conn:
        result = conn.execute(query, {"ticker": ticker})
        row = result.fetchone()
    return dict(row._mapping) if row else None


# ==================== NEWS DATA (MONGODB) ====================

def get_news_for_ticker(ticker: str, limit: int = 20):
    """Zwraca newsy dla danego tickera"""
    cursor = news_col.find({"ticker": ticker}).sort("published", -1).limit(limit)
    return list(cursor)


def update_news_and_sentiment_for_ticker(ticker: str):
    """Pobiera najnowsze newsy + analizuje sentyment"""
    logging.info(f"üîÑ Aktualizacja news√≥w i sentymentu dla {ticker}")
    update_news_for_ticker(ticker)


# ==================== CROSS-INTEGRATION ====================

def sync_user_watchlist_data(user_email: str):
    """
    Synchronizuje dane u≈ºytkownika:
    - pobiera tickery z Supabase
    - ≈Çaduje dane z PostgreSQL
    - aktualizuje newsy z MongoDB
    """
    user = get_user_by_email(user_email)
    if not user:
        logging.warning(f"U≈ºytkownik {user_email} nie istnieje w Supabase.")
        return None

    tickers = get_user_watchlist(user["id"])
    if not tickers:
        logging.info(f"Brak ticker√≥w na watchli≈õcie u≈ºytkownika {user_email}.")
        return None

    all_data = []

    for ticker in tickers:
        stock_data = get_stock_details(ticker)
        news_data = get_news_for_ticker(ticker, limit=5)
        avg_sentiment = None

        if news_data:
            sentiments = [n.get("sentiment", 0) for n in news_data if "sentiment" in n]
            avg_sentiment = round(sum(sentiments) / len(sentiments), 3) if sentiments else None

        all_data.append({
            "ticker": ticker,
            "price": stock_data.get("price") if stock_data else None,
            "market_cap": stock_data.get("market_cap") if stock_data else None,
            "sentiment_avg": avg_sentiment,
            "news_count": len(news_data),
        })

    df = pd.DataFrame(all_data)
    logging.info(f"Zsynchronizowano {len(df)} ticker√≥w dla u≈ºytkownika {user_email}")
    return df


# ==================== SAVE FUNCTIONS ====================

def save_stock_to_pg(df: pd.DataFrame):
    """Bezpieczny zapis danych gie≈Çdowych do PostgreSQL"""
    if df.empty:
        logging.info("Brak danych do zapisania w PostgreSQL")
        return

    # Usu≈Ñ kolumnƒô 'No', je≈õli istnieje
    if 'No' in df.columns:
        df = df.drop(columns=['No'])

    if 'market_cap' in df.columns:
        df['market_cap'] = df['market_cap'].apply(convert_market_cap_idk_why_there)

    # Zmie≈Ñ nazwy kolumn na ma≈Çe litery, usu≈Ñ spacje i znaki specjalne
    df.columns = [c.lower().replace(' ', '_').replace('/', '_').replace('.', '') for c in df.columns]

    metadata = MetaData()
    inspector = inspect(pg_engine)
    table_name = "stocks_data"

    # Sprawd≈∫ czy tabela istnieje
    if not inspector.has_table(table_name):
        logging.info(f"Tabela '{table_name}' nie istnieje ‚Äì tworzƒô nowƒÖ.")
        # Tworzenie tabeli automatycznie z kolumnami z df
        columns = []
        for col in df.columns:
            if df[col].dtype in [int, float]:
                columns.append(Column(col, Float))
            else:
                columns.append(Column(col, String))
        columns.append(Column('import_date', DateTime, default=datetime.utcnow))
        table = Table(table_name, metadata, *columns)
        metadata.create_all(pg_engine)
        logging.info(f"Utworzono tabelƒô '{table_name}' z kolumnami: {df.columns.tolist() + ['import_date']}")
    else:
        table = Table(table_name, metadata, autoload_with=pg_engine)

    # Dodaj kolumnƒô import_date do df
    df['import_date'] = datetime.utcnow()

    # Dopasuj df do kolumn tabeli ‚Äì pomijamy brakujƒÖce w tabeli
    existing_cols = [c.name for c in table.columns]
    df_to_save = df[[c for c in df.columns if c in existing_cols]]

    # Zapis do tabeli
    with pg_engine.begin() as conn:
        try:
            df_to_save.to_sql(table_name, conn, if_exists='append', index=False)
            logging.info(f"Zapisano {len(df_to_save)} rekord√≥w do PostgreSQL")
        except ProgrammingError as e:
            logging.error(f"B≈ÇƒÖd przy zapisie do PostgreSQL: {e}")


def save_news_to_mongo(df: pd.DataFrame, ticker: str):
    """Zapisuje newsy do MongoDB (insert lub update)"""
    from app.db.mongodb import news_col
    if df.empty:
        return
    for _, row in df.iterrows():
        news_col.update_one(
            {"ticker": row["ticker"], "link": row["link"]},
            {"$set": row.to_dict()},
            upsert=True
        )
    logging.info(f"Zapisano/aktualizowano {len(df)} news√≥w w MongoDB")


def save_user_model_results(user_id: str, df: pd.DataFrame):
    """Zapisuje wyniki modelu u≈ºytkownika do Supabase"""
    from app.web.supabase_client import supabase
    if df.empty:
        return
    df['user_id'] = user_id
    data = df.to_dict(orient="records")
    supabase.table("model_results").upsert(data, on_conflict=["user_id", "ticker"]).execute()
    logging.info(f"Zapisano wyniki modelu dla {len(df)} ticker√≥w w Supabase")


def convert_market_cap_idk_why_there(value):
    """Bezpiecznie konwertuje string z kapitalizacjƒÖ rynkowƒÖ na liczbƒô float."""
    if pd.isna(value):
        return None
    value = str(value).strip()
    try:
        if value.endswith('B'):
            return float(value[:-1]) * 1_000_000_000
        elif value.endswith('M'):
            return float(value[:-1]) * 1_000_000
        elif value.endswith('K'):
            return float(value[:-1]) * 1_000
        else:
            return float(value)
    except (ValueError, TypeError):
        return None

def save_stocks_to_csv(df: pd.DataFrame, get_only_tickers=False, with_filters=False) -> None:
    if df is None or df.empty:
        st.error("Brak danych do zapisania.")
        return

    today_str = datetime.now().strftime("%Y%m%d")

    if get_only_tickers:
        # --- SCENARIUSZ 1: ZAPISUJEMY TYLKO TICKERY ---
        logging.info("Tryb 'Tylko tickery'. Zapisywanie uproszczonych danych.")

        path_dir = os.path.join("data", "tickers", today_str)
        filename_suffix = f"finviz_{'filtered_' if with_filters else ''}tickers_{today_str}.csv"

        # Upewniamy siƒô, ≈ºe mamy tylko te dwie kolumny
        df_to_save = df[["No", "Ticker"]].copy()

    else:
        # --- SCENARIUSZ 2: ZAPISUJEMY PE≈ÅNE DANE ---
        logging.info("Tryb pe≈Çnych danych. Przetwarzanie i zapisywanie szczeg√≥≈Çowych informacji.")

        path_dir = os.path.join("data", "stocks", today_str)
        filename_suffix = f"finviz_{'filtered_' if with_filters else ''}stocks_{today_str}.csv"

        df_to_save = df.copy()  # Pracujemy na kopii, aby uniknƒÖƒá problem√≥w z modyfikacjƒÖ

        # Bezpieczne przetwarzanie kolumn (tylko je≈õli istniejƒÖ)
        if "Market Cap" in df_to_save.columns:
            logging.info(f"Kolumny w DataFrame: {df_to_save.columns.tolist()}")
            logging.info(
                f"Pierwsze 5 warto≈õci 'Market Cap' (przed konwersjƒÖ): {df_to_save['Market Cap'].head().tolist()}")
            df_to_save['market_cap_numeric'] = df_to_save['Market Cap'].apply(convert_market_cap)
            logging.info(
                f"Pierwsze 5 warto≈õci 'market_cap_numeric' (po konwersji): {df_to_save['market_cap_numeric'].head().tolist()}")

        numeric_cols = ["Price", "Volume", "52w High", "52w Low", "P/E", "Rel Vol"]
        for col in numeric_cols:
            if col in df_to_save.columns:
                df_to_save[col] = pd.to_numeric(df_to_save[col].astype(str).str.replace(",", "", regex=False),
                                                errors="coerce")

        percent_cols = ["EPS next 5Y", "Perf Week", "Perf Month", "Change"]
        for col in percent_cols:
            if col in df_to_save.columns:
                df_to_save[col] = pd.to_numeric(df_to_save[col].astype(str).str.replace("%", "", regex=False),
                                                errors="coerce") / 100.0

    # Krok 2: Utw√≥rz katalog i zapisz plik
    try:
        os.makedirs(path_dir, exist_ok=True)
        full_path = os.path.join(path_dir, filename_suffix)

        df_to_save.to_csv(full_path, index=False)
        logging.info(f"Dane pomy≈õlnie zapisane do: {full_path}")
        st.toast(f"Zapisano plik: {filename_suffix}", icon="üíæ")

    except Exception as e:
        logging.error(f"Nie uda≈Ço siƒô zapisaƒá pliku {filename_suffix}. B≈ÇƒÖd: {e}")
        st.error(f"B≈ÇƒÖd zapisu pliku: {e}")